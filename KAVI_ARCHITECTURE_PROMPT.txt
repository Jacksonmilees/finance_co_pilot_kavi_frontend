Finance Co-Pilot KAVI is a production-ready SaaS financial management platform for Kenyan SMEs, built as a modern full-stack web application with a React 18.2.0 frontend using Vite 7.2.2 as the build tool, TailwindCSS 3.2.7 for styling, shadcn/ui components built on Radix UI, React Router 6.8.1 for client-side routing, TanStack Query 4.42.0 for data fetching and caching, Zustand 5.0.8 for state management, Axios 1.13.2 as the HTTP client, Lucide React for icons, and React Hot Toast for notifications, all communicating with a Django 5.2.6 backend API built using Django REST Framework 3.16.1 that implements JWT authentication via SimpleJWT, connects to a PostgreSQL 15+ database for data persistence, uses django-cors-headers for cross-origin resource sharing, and integrates with external AI services including Google Gemini AI for conversational intelligence and natural language processing, ElevenLabs for text-to-speech voice synthesis, and the browser's Web Speech API for speech recognition to power KAVI the AI voice assistant. The application is designed to be deployed on AWS infrastructure using AWS ECS Fargate for container orchestration running Docker containers in a VPC with CIDR block 10.0.0.0/16 distributed across two availability zones, each containing public subnets (10.0.1.0/24 and 10.0.3.0/24) with NAT Gateways and private subnets (10.0.2.0/24 and 10.0.4.0/24) hosting the ECS tasks, with an Application Load Balancer distributing traffic to the backend Django container (0.5 vCPU, 1GB RAM) running on port 8000, while static assets from the React frontend build are hosted on Amazon S3 and served globally via AWS CloudFront CDN with SSL/TLS termination using certificates from AWS Certificate Manager, DNS management through AWS Route 53 for the domain financegrowth.co.ke, database hosting on Amazon RDS PostgreSQL db.t3.micro instance configured with Multi-AZ deployment for high availability in a dedicated database subnet group spanning both availability zones with automated daily backups retained for 7 days, container images stored in Amazon ECR, application secrets and API keys secured in AWS Secrets Manager, comprehensive monitoring and logging through Amazon CloudWatch with custom dashboards tracking ECS CPU/memory utilization, ALB response times and error rates, RDS performance metrics, and application-level logs, automated backups managed by AWS Backup, optional AWS WAF for web application firewall protection, and AWS X-Ray for distributed tracing. The system implements a six-layer security architecture starting with network security using AWS WAF, DDoS protection via AWS Shield, VPC isolation with security groups allowing only port 443 from the internet to the ALB, ALB to ECS communication on port 8000, and ECS to RDS on port 5432, transport security with HTTPS only enforcing TLS 1.3 and HTTP Strict Transport Security headers, application security with JWT token authentication, token refresh mechanisms, CORS policy enforcement, CSRF protection, XSS protection headers, and SQL injection prevention through Django ORM, access control implementing role-based permissions with a three-tier system (Super Admin, Business Admin, and Staff/Viewer roles) with business-level and user-level data isolation, data security featuring database encryption at rest for RDS, S3 bucket encryption for stored objects, password hashing using Django's PBKDF2 algorithm, and sensitive data masking, plus monitoring and auditing through comprehensive activity logging, failed login attempt tracking, session monitoring, CloudWatch logs, AWS CloudTrail audit trails, and optional AWS GuardDuty for intrusion detection. The data flow begins when users access the platform through web browsers, mobile devices, or tablets via HTTPS, with requests routed through CloudFront to the ALB which distributes traffic to ECS Fargate tasks, where the Django backend authenticates requests using JWT tokens, queries the PostgreSQL database through the Django ORM spanning 15+ tables including auth_user, user_profiles, businesses, customers, memberships, invitations, registrations in the users schema, transactions, invoices, invoice_items, budgets, cash_flows, forecasts, credit_scores, and suppliers tables in the finance schema, and activity_logs, user_sessions, failed_logins, and module_assignments in the core schema, processes business logic including financial calculations, budget tracking, invoice generation, cash flow forecasting, and credit score monitoring, and returns JSON responses that the React frontend caches using TanStack Query, updates the UI state via Zustand, and renders using responsive TailwindCSS components, while KAVI voice interactions follow a specialized flow where the user speaks into their device triggering the Web Speech API to convert voice to text, the frontend sends the text along with user context (user_id, business_id, recent financial data) to the backend which fetches the last 30 days of transactions, current budget status, pending invoices, and credit score information, calls the Google Gemini AI API with this enriched context to generate a personalized response based on actual user data rather than generic advice, returns the AI-generated text response to the frontend which displays it in the chat interface and simultaneously calls the ElevenLabs API to convert the text to natural-sounding speech audio that plays back to the user. The deployment pipeline uses a CI/CD workflow starting from the developer's workstation where code is pushed to a GitHub repository triggering a webhook to GitHub Actions or AWS CodePipeline which runs automated tests, lints the code using ESLint and Prettier for frontend and Black for backend Python code, performs security scans, and upon successful validation enters the build stage where the React frontend is built using Vite producing optimized static assets, the Django backend is containerized using Docker with an Alpine Linux base image, both container images are pushed to Amazon ECR, then the deploy stage updates the ECS task definitions with new image tags, deploys to a staging environment, runs smoke tests to verify health endpoints, and upon passing all staging tests executes a blue-green deployment to production with health checks monitoring the new task instances and automatic rollback capability if health checks fail, ensuring zero-downtime deployments. The system is designed to scale horizontally using ECS auto-scaling policies triggered by CPU and memory thresholds with a minimum of 2 tasks and maximum of 10 tasks for the MVP phase, database optimization through connection pooling and query optimization with indexes on frequently queried fields like business_id and transaction_date with plans for read replicas when scaling beyond 1000 users, a multi-tier caching strategy using CloudFront CDN for static assets, application-level caching planned with Redis for session storage and frequently accessed data, browser caching headers for client-side caching, and database query result caching, plus load balancing through the Application Load Balancer distributing traffic across multiple availability zones with health checks every 30 seconds and automatic failover to healthy instances, session affinity using sticky sessions when needed, and path-based routing to different backend services. The estimated monthly infrastructure cost for the MVP supporting 0-100 users is approximately $115 including $40 for ECS Fargate running 2 tasks at 0.5 vCPU and 1GB RAM each, $20 for RDS PostgreSQL db.t3.micro with Multi-AZ deployment, $10 for S3 storage and CloudFront data transfer for approximately 100GB monthly, $20 for the Application Load Balancer, $1 for Route 53 hosted zone, $7 for CloudWatch monitoring and logs, $2 for AWS Secrets Manager storing 10 secrets, and $15 for data transfer costs, scaling to approximately $222 per month when supporting 1000 users with 5-8 ECS tasks ($110), RDS db.t3.small instance ($40), increased S3 and CloudFront usage ($22), and other supporting services ($50), with a clear path to $500-800 monthly for 1000-10,000 users and $1000+ for enterprise scale beyond 10,000 users. The application implements comprehensive monitoring with CloudWatch dashboards displaying real-time metrics for application performance (API response times with targets under 200ms, error rates targeting under 0.1%, throughput measured in requests per second), infrastructure health (ECS CPU and memory utilization, ALB target response times and request counts, ALB 4XX/5XX error rates, RDS CPU utilization and database connection counts), and business metrics (user activity, transaction volume, KAVI conversation rates, invoice generation statistics), with critical alarms configured for ALB 5XX errors exceeding 5% for 5 minutes, RDS CPU above 90% for 10 minutes, ECS task failures exceeding 2 in 5 minutes, and application errors surpassing 10 per minute triggering PagerDuty or SNS notifications, plus warning alarms for ALB response times averaging over 1 second for 15 minutes, RDS connections exceeding 80% of maximum capacity, S3 bucket sizes reaching 80% of expected quota, and ECS CPU above 70% for 30 minutes sending email notifications to the operations team. The disaster recovery strategy includes automated RDS snapshots taken daily with 7-day retention and cross-region backup to a secondary AWS region, point-in-time recovery enabled for the database allowing restoration to any point within the backup retention period, S3 versioning enabled for all buckets protecting against accidental deletions with lifecycle policies to archive old versions, infrastructure as code stored in Git repositories ensuring all AWS resources can be recreated quickly, recovery time objectives (RTO) of less than 15 minutes for database failures using Multi-AZ automatic failover, less than 5 minutes for application failures leveraging ECS auto-recovery and ALB health checks, and less than 2 hours for complete region failure by promoting the secondary region, with recovery point objectives (RPO) of less than 5 minutes for database using automated backups, less than 1 hour for user uploads using S3 versioning, and zero for configuration since everything is version controlled in Git. The platform currently serves Kenyan SMEs with features including real-time financial dashboards customized by user role showing key metrics like monthly revenue, expenses, profit margins, cash flow trends, upcoming invoice due dates, budget utilization percentages, and credit score changes, transaction management supporting income and expense tracking with M-Pesa integration, category tagging, receipt attachments stored in S3, reference number tracking, and external ID linkage to bank statements, invoice management with automated invoice number generation, PDF export capabilities, email delivery to customers, payment tracking, overdue notifications, and eTIMS integration for tax compliance, cash flow forecasting using AI-powered 30-day predictions analyzing historical transaction patterns, seasonal trends, pending invoices, and recurring expenses, credit score tracking monitoring business creditworthiness with scoring algorithms based on payment history, debt-to-income ratios, transaction consistency, and external credit bureau data when available, budget management allowing users to set monthly budgets by category with real-time tracking, spending alerts when approaching limits, variance analysis comparing actual versus budgeted amounts, and recommendations for budget optimization, supplier management maintaining a database of vendors with reliability scores calculated from on-time delivery rates, payment terms, product quality ratings, and transaction history, team collaboration supporting multi-user access with email-based invitations, role assignment (Business Admin can view and edit all data, Staff can create transactions and invoices, Viewer can only read data), activity tracking showing who created or modified each record with timestamps, and business-level data isolation ensuring users only see data for businesses they have been granted access to, plus customer relationship management tracking customer details, transaction history, outstanding invoices, payment patterns, and communication logs, all built with a mobile-first responsive design using TailwindCSS breakpoints ensuring the interface works seamlessly on devices from 320px width smartphones to large desktop monitors, touch-optimized buttons with minimum 44px tap targets, custom scrollbars for better mobile experience, smooth animations and transitions enhancing perceived performance, PWA readiness allowing installation as a standalone app on mobile devices, and optimization for slow 3G networks common in rural Kenya through lazy loading components, image compression, code splitting, and cached API responses reducing data usage and improving load times even on poor connectivity.
